\section{Introduction}\label{sec:intro}

A \textit{conformance test} suite is essential to support consistent execution
environments for JavaScript.
%
While JavaScript was a simple scripting language for client-side programming in
web browsers, it has now become one of the most popular programming languages.
%
It happens because diverse host environments support JavaScript engines for
server-side programming, cross-platform desktop or mobile applications, PDF
files, and even embedded systems.
%
For a consistent execution environment anywhere, JavaScript engines must conform
to ECMA-262~\cite{es13}, the official ECMAScript language specification.
%
It defines JavaScript syntax in a variant of the extended Backusâ€“Naur form
(EBNF) and the language semantics using abstract algorithms consisting of
well-organized English sentences as steps.
%
To check the conformance between the specification and JavaScript engines,
developers usually utilized Test262~\cite{test262}, the official conformance
test suite.
%
It consists of JavaScript programs with assertions that check the expected
behaviors according to the language semantics described in the specification.
%
Unfortunately, Test262 is manually maintained without any automated check for
the correctness of the test programs.
%
Therefore, it is labor-intensive to maintain them as strictly conforming to the
specification by hand.

%----------------------------------------%

However, it is challenging to automatically synthesize correct JavaScript
conformance tests.
%
First, JavaScript has complex language semantics with a highly dynamic nature.
%
For example, it supports first-class functions, first-class property names,
implicit control flows (e.g., getters/setters), asynchronous function calls
(\code{Promise}), mutable prototypes, and even dynamic code execution
(\code{eval}).
%
Such complex semantics make it difficult to cover all possible edge cases in the
semantics of various language features.
%
Second, JavaScript is fast-evolving with new language features, while its
language specification is written in a natural language.
%
Since 2015, ECMA-262 is annually released to quickly adapt users' demands to the
language.
%
Already eight major versions of ECMA-262 have been released, and the
latest version (ES13, 2022) is 846 pages.

%----------------------------------------%

Therefore, most prior work~\cite{montage, langfuzz, die, favocado,
codealchemist, sofi} only focuses on the detection of crashing bugs or
vulnerabilities rather than conformance bugs in JavaScript engines.
%
Existing techniques utilize fuzz testing (or fuzzing), widely used in compiler
bug detection by randomly generating or mutating test inputs.
%
Even though they show outstanding results in detecting crash bugs or
vulnerabilities in JavaScript engines, they almost neglect the detection of
conformance bugs.
%
On the other hand, $\comfort$~\cite{comfort} targets conformance bugs by
leveraging a deep-learning-based program synthesis~\cite{deep-smith} and
differential testing with multiple JavaScript engines.
%
However, it heavily relies on the results of differential testing instead of the
language semantics described in ECMA-262.

%----------------------------------------%

\paragraph{\textbf{Challenges}}
%
Unlike other fuzzers on JavaScript engines, $\jest$~\cite{jest} automatically
synthesizes conformance tests directly from a given version of ECMA-262 without
any engines.
%
It first synthesizes JavaScript programs using coverage-guided
fuzzing~\cite{afl} with the control-flow graph (CFG) in the language
specification. 
%
Then, it automatically injects assertions into the synthesized programs based on
their expected final states in the language specification.
%
While it has a remarkable result in detecting conformance bugs, it still has two
limitations: 1) \textit{removal of meaningful conformance tests} and 2)
\textit{no consideration of transpilers}.

%----------------------------------------%

First, the prior work utilizes simple \textit{node/branch coverages}, and we
found that they remove meaningful conformance tests in the final test suite.
%
In the JavaScript language specification, the semantics of different language
features often share the same abstract algorithms.
%
However, node/branch coverages are context-insensitive, and their test
requirements are just nodes or branches in the CFG in the language
specification.
%
It means that they are not enough to distinguish the semantics of different
language features defined with shared abstract algorithms in the specification.
%
As a result, it lweakens the fuzzing guidance and even remove meaningful test
programs in the final test suite.
%
In addition, even different parts in the semantics of the same language features
often share the same abstract algorithms, which deepens the problem.
%
We describe more details of these problems with simple examples in
Section~\ref{sec:motivation}.

%----------------------------------------%

Second, prior work focuses on conformance checks only for engines but does not
consider \textit{transpilers}.
%
Recently, developers heavily utilize JavaScript transpilers as well as engines,
and they have become essential tools in the deployment process of JavaScript
applications for various purposes.
%
For example, Babel and SWC desugar new language features into
backward-compatible versions of the language mainly for legacy web browsers.
%
The code compressors compress code size to reduce the network communication
cost, and JavaScript Obfuscator obfuscates code to make it hard to understand
and reverse-engineering.
%
Therefore, ensuring the conformance of transpilers becomes crucial more and
more.


%----------------------------------------%

\paragraph{\textbf{This Work}}

This paper introduces a novel \textit{feature-sensitive coverage}, which
discriminates the test requirements with their enclosing language features.
%
We observe that specific abstract algorithms in the JavaScript language
specification are coupled with language features.
%
We utilize this information to enhance the quality of the coverage-guided
fuzzing for conformance test synthesis.
%
First, we formally define a basic feature-sensitive coverage as a general
extension of any coverage metrics.
%
It could discriminate the semantics of different language features defined with
shared abstract algorithms in the specification.
%
In addition, we define its variants with simple call paths from language
features to distinguish different parts in the semantics of the same language
features.
%
We implemented $\tool$ by extending a state-of-the-art JavaScript conformance
test synthesizer, $\jest$, with our feature-sensitive coverage.
%
For the latest language specification (ES13, 2022), our tool automatically
synthesized \inred{5,000} conformance tests in \inred{100} hours.
%
We checked conformance of not only engines but also transpilers with the
synthesized conformance tests for evaluation.
%
The evaluation targets were \inred{eight} mainstream tools (\inred{four} engines
and \inred{four} transpilers), and we discovered bugs in all of them.
%
Our tool detected \inred{50} unique conformance bugs (\inred{20} in engines and
\inred{30} in transpilers), while the baseline tool detected only \inred{16}
engine bugs.
%
We had reported all detected bugs, developers confirmed all of them, and
\inred{40} were newly discovered bugs.
%
\inred{Furthermore, 25 test cases were added to Test262, the official JavaScript
conformance test suite.}

%----------------------------------------%

\paragraph{\textbf{Contributions}}
%
We summarize our contributions as follows:
%
\begin{itemize}

  \item
    We introduce a novel \textit{feature-sensitive coverage} to discriminate
    test requirements with their enclosing language features.
    %
    We also define its variants with simple call paths from language features to
    distinguish different parts in the semantics of the same language features.

  \item
    We extended $\jest$ to $\tool$ with the feature-sensitive coverage, and it
    is the first work to check conformance not only for engines but also for
    transpilers.

  \item
    We experimentally show that our tool outperforms the baseline tool in the
    context of conformance bug detection in \inred{eight} mainstream targets
    (\inred{four} engines and \inred{four} transpilers) with the latest ECMA-262
    (ES13, 2022).
    %
    As a result, $\tool$ detected \inred{50} unique conformance bugs (\inred{20}
    in engines and \inred{30} in transpilers), while the baseline tool detected
    only \inred{16} engine bugs.
\end{itemize}
